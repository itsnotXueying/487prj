{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from helpy_train import *\n",
    "import helpy_log\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import gensim.downloader\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from dataset_old import *\n",
    "from mlp import *\n",
    "# from mlp_bucket import *\n",
    "# from dataset_bucketing import *\n",
    "# from dataset_ingre_bucket import *\n",
    "\n",
    "\n",
    "punks = string.punctuation\n",
    "punks = punks+ '``'+ \"''\"\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.manual_seed(88)\n",
    "np.random.seed(88)\n",
    "random.seed(88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trial(batch_size_in, learning_rate_in, momentum_in, weight_decay_in, save_folder, reg):\n",
    "    print(f'save_folder:{save_folder}')\n",
    "    \n",
    "    device = f\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    tr_loader,va_loader,te_loader  = get_train_val_test_loaders(batch_size_in)\n",
    "    \n",
    "    model = MLP()\n",
    "    model.to(device)\n",
    "\n",
    "    \n",
    "    start_epoch = 0\n",
    "    stats = []\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate_in, weight_decay=weight_decay_in)\n",
    "\n",
    "    #axes,fig = helpy_log.make_training_plot(batch_size_in, learning_rate_in, momentum_in, weight_decay_in)\n",
    "\n",
    "    saved_path = os.path.join(save_folder,\n",
    "                              f\"b{batch_size_in}_lr{learning_rate_in}_p{momentum_in}_wd{weight_decay_in}\")\n",
    "    info = {\"batch\":batch_size_in, \"lr\":learning_rate_in,\"p\": momentum_in, \"wd\": weight_decay_in}\n",
    "    \n",
    "    if not os.path.exists(saved_path):\n",
    "        os.makedirs(saved_path, exist_ok=True)\n",
    "    \n",
    "    \n",
    "    print(\"inital eval\")\n",
    "    evaluate_epoch(tr_loader, va_loader, te_loader, model, criterion, start_epoch, stats,\n",
    "                   device,info, save_folder,reg)\n",
    "\n",
    "\n",
    "    global_min_loss = stats[-1][-2]\n",
    "    \n",
    "    patience = 5\n",
    "    curr_count_to_patience = 0\n",
    "    \n",
    "    # Loop over the entire dataset multiple times\n",
    "    epoch = start_epoch\n",
    "    print(f\"Entering train loop for lr:{learning_rate_in} p:{momentum_in} wd:{weight_decay_in}\")\n",
    "    while curr_count_to_patience < patience:\n",
    "        print(f\"starting epoch {epoch}\")\n",
    "        \n",
    "        # Train model\n",
    "        train_epoch(tr_loader, model, criterion, optimizer, device)\n",
    "\n",
    "        # Evaluate model\n",
    "        evaluate_epoch(tr_loader, va_loader, te_loader,model, criterion, epoch + 1, stats,\n",
    "                       device, info, save_folder,reg)\n",
    "\n",
    "        # Save model parameters\n",
    "        save_checkpoint(model, epoch + 1, save_folder, stats, info)\n",
    "\n",
    "        if epoch > 8:\n",
    "            curr_count_to_patience, global_min_loss = early_stopping(stats, curr_count_to_patience, global_min_loss)\n",
    "        epoch += 1\n",
    "    print(f\"Finished Training after {epoch} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_folder:results_mlp_ingre_regression\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 131207.78125\n",
      "val loss 62634.99609375\n",
      "test loss 546923.5\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.8 wd:0.0001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 151207.21875\n",
      "val loss 52360.0859375\n",
      "test loss 498790.65625\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 724225.1875\n",
      "val loss 52329.81640625\n",
      "test loss 500212.78125\n",
      "\n",
      "starting epoch 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gkondas/EECS487/final/here.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trial(\u001b[39m64\u001b[39;49m, \u001b[39m1e-3\u001b[39;49m, \u001b[39m0.8\u001b[39;49m, \u001b[39m1e-4\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mresults_mlp_ingre_regression\u001b[39;49m\u001b[39m'\u001b[39;49m,reg\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;32m/home/gkondas/EECS487/final/here.ipynb Cell 3\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstarting epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=43'>44</a>\u001b[0m train_epoch(tr_loader, model, criterion, optimizer, device)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# Evaluate model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=46'>47</a>\u001b[0m evaluate_epoch(tr_loader, va_loader, te_loader,model, criterion, epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, stats,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/gkondas/EECS487/final/here.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=47'>48</a>\u001b[0m                device, info, save_folder,reg)\n",
      "File \u001b[0;32m~/EECS487/final/helpy_train.py:199\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(data_loader, model, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_epoch\u001b[39m(data_loader, model, criterion, optimizer, device):\n\u001b[1;32m    198\u001b[0m     model\u001b[39m.\u001b[39mtrain()              \n\u001b[0;32m--> 199\u001b[0m     \u001b[39mfor\u001b[39;00m i, (X, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(data_loader):\n\u001b[1;32m    200\u001b[0m         X,y \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    201\u001b[0m         y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/EECS487/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/EECS487/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1327\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1328\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1330\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1331\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/EECS487/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1294\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1293\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1294\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1295\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1296\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/EECS487/env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1120\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1133\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1134\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1135\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    114\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/usr/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trial(64, 1e-3, 0.8, 1e-4,'results_mlp_ingre_regression',reg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c168b246a33f417ba3e7efdd630c5502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6290000081062317\n",
      "val loss 0.6299999952316284\n",
      "test loss 0.6299999952316284\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.8 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 60.34700012207031\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 60.45800018310547\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 60.560001373291016\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 59.88600158691406\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 60.27399826049805\n",
      "val loss 60.73899841308594\n",
      "test loss 60.042999267578125\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 48.95800018310547\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 48.95800018310547\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 49.08100128173828\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 49.55099868774414\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 49.44900131225586\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 49.28499984741211\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 48.775001525878906\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 49.40800094604492\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 49.46900177001953\n",
      "val loss 49.42300033569336\n",
      "test loss 50.025001525878906\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6010000109672546\n",
      "val loss 0.6000000238418579\n",
      "test loss 0.6019999980926514\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.8 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 23.780000686645508\n",
      "val loss 22.94099998474121\n",
      "test loss 23.1299991607666\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 24.308000564575195\n",
      "val loss 22.951000213623047\n",
      "test loss 23.1560001373291\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 23.882999420166016\n",
      "val loss 22.667999267578125\n",
      "test loss 22.969999313354492\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 24.202999114990234\n",
      "val loss 22.670000076293945\n",
      "test loss 22.97100067138672\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 23.628000259399414\n",
      "val loss 22.656999588012695\n",
      "test loss 22.961000442504883\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 24.386999130249023\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 24.121999740600586\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 24.448999404907227\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 23.202999114990234\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 23.672000885009766\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 24.142000198364258\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 24.551000595092773\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 24.040000915527344\n",
      "val loss 23.14699935913086\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 23.937999725341797\n",
      "val loss 23.128000259399414\n",
      "test loss 23.2450008392334\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6100000143051147\n",
      "val loss 0.6079999804496765\n",
      "test loss 0.609000027179718\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.8 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 23.836000442504883\n",
      "val loss 23.14900016784668\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 23.815000534057617\n",
      "val loss 23.152000427246094\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 23.447999954223633\n",
      "val loss 23.15399932861328\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 24.08099937438965\n",
      "val loss 23.15399932861328\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 23.999000549316406\n",
      "val loss 23.152999877929688\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 23.590999603271484\n",
      "val loss 23.152999877929688\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 23.89699935913086\n",
      "val loss 23.152000427246094\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 24.81599998474121\n",
      "val loss 23.152999877929688\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 24.386999130249023\n",
      "val loss 23.152999877929688\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 23.91699981689453\n",
      "val loss 23.152000427246094\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 23.34600067138672\n",
      "val loss 23.152000427246094\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 23.836000442504883\n",
      "val loss 23.150999069213867\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 23.202999114990234\n",
      "val loss 23.150999069213867\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 24.020000457763672\n",
      "val loss 23.149999618530273\n",
      "test loss 23.2450008392334\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.593999981880188\n",
      "val loss 0.5910000205039978\n",
      "test loss 0.593999981880188\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.9 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 24.448999404907227\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 24.142000198364258\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 23.672000885009766\n",
      "val loss 23.155000686645508\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 23.222999572753906\n",
      "val loss 23.141000747680664\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 23.365999221801758\n",
      "val loss 23.131000518798828\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 24.160999298095703\n",
      "val loss 23.077999114990234\n",
      "test loss 23.243999481201172\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 23.895999908447266\n",
      "val loss 22.945999145507812\n",
      "test loss 23.166000366210938\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 60.35499954223633\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 59.784000396728516\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 60.25299835205078\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 60.4370002746582\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 60.13100051879883\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 60.35499954223633\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 61.2130012512207\n",
      "val loss 60.73899841308594\n",
      "test loss 60.0629997253418\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6069999933242798\n",
      "val loss 0.6029999852180481\n",
      "test loss 0.6069999933242798\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.9 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 24.183000564575195\n",
      "val loss 23.04400062561035\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 23.98200035095215\n",
      "val loss 23.100000381469727\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 23.652000427246094\n",
      "val loss 23.114999771118164\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 23.448999404907227\n",
      "val loss 23.1299991607666\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 24.0\n",
      "val loss 23.1299991607666\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 23.694000244140625\n",
      "val loss 23.131000518798828\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 23.753999710083008\n",
      "val loss 23.131000518798828\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 23.549999237060547\n",
      "val loss 23.131999969482422\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 23.714000701904297\n",
      "val loss 23.132999420166016\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 24.041000366210938\n",
      "val loss 23.132999420166016\n",
      "test loss 23.246000289916992\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 23.400999069213867\n",
      "val loss 23.090999603271484\n",
      "test loss 23.215999603271484\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 23.81999969482422\n",
      "val loss 22.989999771118164\n",
      "test loss 23.134000778198242\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 23.795000076293945\n",
      "val loss 22.885000228881836\n",
      "test loss 23.06100082397461\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 24.677000045776367\n",
      "val loss 22.79599952697754\n",
      "test loss 23.0\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.652999997138977\n",
      "val loss 0.652999997138977\n",
      "test loss 0.6510000228881836\n",
      "\n",
      "Entering train loop for lr:0.1 p:0.9 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 23.795000076293945\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 24.448999404907227\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 23.652000427246094\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 23.91699981689453\n",
      "val loss 23.17099952697754\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 23.937999725341797\n",
      "val loss 23.170000076293945\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 23.91699981689453\n",
      "val loss 23.16699981689453\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 23.71299934387207\n",
      "val loss 23.163999557495117\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 23.406999588012695\n",
      "val loss 23.163000106811523\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 23.815000534057617\n",
      "val loss 23.16200065612793\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 24.183000564575195\n",
      "val loss 23.160999298095703\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 23.610000610351562\n",
      "val loss 23.15999984741211\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 23.672000885009766\n",
      "val loss 23.159000396728516\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 24.03700065612793\n",
      "val loss 23.158000946044922\n",
      "test loss 23.2450008392334\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 23.566999435424805\n",
      "val loss 23.158000946044922\n",
      "test loss 23.2450008392334\n",
      "\n",
      "Finished Training after 14 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6729999780654907\n",
      "val loss 0.675000011920929\n",
      "test loss 0.6700000166893005\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.8 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5320000052452087\n",
      "test loss 0.5339999794960022\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5299999713897705\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5350000262260437\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5379999876022339\n",
      "val loss 0.531000018119812\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.531000018119812\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.5299999713897705\n",
      "val loss 0.5249999761581421\n",
      "test loss 0.5270000100135803\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.5289999842643738\n",
      "val loss 0.5249999761581421\n",
      "test loss 0.5270000100135803\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.5260000228881836\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5299999713897705\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5260000228881836\n",
      "test loss 0.527999997138977\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5350000262260437\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.5320000052452087\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.5350000262260437\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 16\n",
      "Epoch:17\n",
      "train loss 0.5320000052452087\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "Finished Training after 17 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.7039999961853027\n",
      "val loss 0.7049999833106995\n",
      "test loss 0.703000009059906\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.8 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5059999823570251\n",
      "val loss 0.5120000243186951\n",
      "test loss 0.5070000290870667\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5090000033378601\n",
      "val loss 0.5109999775886536\n",
      "test loss 0.5080000162124634\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.5040000081062317\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5019999742507935\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.503000020980835\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.49900001287460327\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.5059999823570251\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.4950000047683716\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5090000033378601\n",
      "val loss 0.5070000290870667\n",
      "test loss 0.5040000081062317\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5109999775886536\n",
      "val loss 0.5070000290870667\n",
      "test loss 0.5019999742507935\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5139999985694885\n",
      "val loss 0.5080000162124634\n",
      "test loss 0.5109999775886536\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49900001287460327\n",
      "\n",
      "Finished Training after 15 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6740000247955322\n",
      "val loss 0.6759999990463257\n",
      "test loss 0.6740000247955322\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.8 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.49900001287460327\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5040000081062317\n",
      "val loss 0.503000020980835\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5049999952316284\n",
      "val loss 0.5080000162124634\n",
      "test loss 0.5040000081062317\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5019999742507935\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.4869999885559082\n",
      "val loss 0.49399998784065247\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.5\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5360000133514404\n",
      "val loss 0.5260000228881836\n",
      "test loss 0.5210000276565552\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.48899999260902405\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.4950000047683716\n",
      "test loss 0.48899999260902405\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.48899999260902405\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 16\n",
      "Epoch:17\n",
      "train loss 0.4970000088214874\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 17\n",
      "Epoch:18\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.503000020980835\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "starting epoch 18\n",
      "Epoch:19\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "Finished Training after 19 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6259999871253967\n",
      "val loss 0.6240000128746033\n",
      "test loss 0.628000020980835\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.9 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.531000018119812\n",
      "val loss 0.5249999761581421\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.531000018119812\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5299999713897705\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.531000018119812\n",
      "val loss 0.5249999761581421\n",
      "test loss 0.5270000100135803\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.5299999713897705\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.527999997138977\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.5400000214576721\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5320000052452087\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5289999842643738\n",
      "\n",
      "Finished Training after 16 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.7039999961853027\n",
      "val loss 0.7039999961853027\n",
      "test loss 0.7009999752044678\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.9 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5070000290870667\n",
      "val loss 0.5070000290870667\n",
      "test loss 0.5019999742507935\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5019999742507935\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.5\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.4970000088214874\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.5189999938011169\n",
      "val loss 0.5139999985694885\n",
      "test loss 0.5090000033378601\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.503000020980835\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.5569999814033508\n",
      "val loss 0.5559999942779541\n",
      "test loss 0.5460000038146973\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.5049999952316284\n",
      "test loss 0.5019999742507935\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5049999952316284\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5099999904632568\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.5\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.5170000195503235\n",
      "val loss 0.5070000290870667\n",
      "test loss 0.5099999904632568\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.5049999952316284\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.5070000290870667\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "Finished Training after 16 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6230000257492065\n",
      "val loss 0.6230000257492065\n",
      "test loss 0.625\n",
      "\n",
      "Entering train loop for lr:0.01 p:0.9 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5429999828338623\n",
      "val loss 0.5600000023841858\n",
      "test loss 0.5490000247955322\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5049999952316284\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.5059999823570251\n",
      "val loss 0.5\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5059999823570251\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.49300000071525574\n",
      "test loss 0.48899999260902405\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.503000020980835\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.49799999594688416\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.4970000088214874\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.4970000088214874\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.48899999260902405\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.492000013589859\n",
      "\n",
      "Finished Training after 15 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6549999713897705\n",
      "val loss 0.6570000052452087\n",
      "test loss 0.6549999713897705\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.8 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5619999766349792\n",
      "val loss 0.5569999814033508\n",
      "test loss 0.5649999976158142\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5580000281333923\n",
      "val loss 0.5460000038146973\n",
      "test loss 0.5540000200271606\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.550000011920929\n",
      "val loss 0.5419999957084656\n",
      "test loss 0.5479999780654907\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.546999990940094\n",
      "val loss 0.5370000004768372\n",
      "test loss 0.5429999828338623\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.5400000214576721\n",
      "val loss 0.5379999876022339\n",
      "test loss 0.5419999957084656\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5379999876022339\n",
      "val loss 0.5320000052452087\n",
      "test loss 0.5370000004768372\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.531000018119812\n",
      "test loss 0.5350000262260437\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5339999794960022\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.5379999876022339\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5329999923706055\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5360000133514404\n",
      "val loss 0.527999997138977\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5270000100135803\n",
      "test loss 0.5299999713897705\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.527999997138977\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "Finished Training after 16 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.628000020980835\n",
      "val loss 0.628000020980835\n",
      "test loss 0.6269999742507935\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.8 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5230000019073486\n",
      "val loss 0.5199999809265137\n",
      "test loss 0.5199999809265137\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5059999823570251\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.5\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.503000020980835\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.492000013589859\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.49900001287460327\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.5\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.4950000047683716\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.49300000071525574\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.5\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.48899999260902405\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.492000013589859\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "Finished Training after 16 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6159999966621399\n",
      "val loss 0.6159999966621399\n",
      "test loss 0.6159999966621399\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.8 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5120000243186951\n",
      "val loss 0.5109999775886536\n",
      "test loss 0.5059999823570251\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.4880000054836273\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.4880000054836273\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.4869999885559082\n",
      "val loss 0.5\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.4790000021457672\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.5090000033378601\n",
      "test loss 0.5019999742507935\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.4880000054836273\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.4860000014305115\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.4860000014305115\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.48399999737739563\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.49300000071525574\n",
      "val loss 0.5\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.47699999809265137\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.48500001430511475\n",
      "val loss 0.5\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.4830000102519989\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.4819999933242798\n",
      "val loss 0.5\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 16\n",
      "Epoch:17\n",
      "train loss 0.47099998593330383\n",
      "val loss 0.5059999823570251\n",
      "test loss 0.4950000047683716\n",
      "\n",
      "Finished Training after 17 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6489999890327454\n",
      "val loss 0.6499999761581421\n",
      "test loss 0.6520000100135803\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.9 wd:0.1\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.5799999833106995\n",
      "val loss 0.5690000057220459\n",
      "test loss 0.578000009059906\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5619999766349792\n",
      "val loss 0.5590000152587891\n",
      "test loss 0.5659999847412109\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5519999861717224\n",
      "val loss 0.550000011920929\n",
      "test loss 0.5559999942779541\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.550000011920929\n",
      "val loss 0.546999990940094\n",
      "test loss 0.5519999861717224\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.546999990940094\n",
      "val loss 0.5389999747276306\n",
      "test loss 0.5450000166893005\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.5429999828338623\n",
      "val loss 0.5370000004768372\n",
      "test loss 0.5419999957084656\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.5389999747276306\n",
      "val loss 0.5350000262260437\n",
      "test loss 0.5400000214576721\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.5329999923706055\n",
      "test loss 0.5370000004768372\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.5379999876022339\n",
      "val loss 0.5320000052452087\n",
      "test loss 0.5360000133514404\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.5370000004768372\n",
      "val loss 0.531000018119812\n",
      "test loss 0.5339999794960022\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5389999747276306\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5339999794960022\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.5379999876022339\n",
      "val loss 0.5299999713897705\n",
      "test loss 0.5329999923706055\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.527999997138977\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.5350000262260437\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.5320000052452087\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.527999997138977\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 16\n",
      "Epoch:17\n",
      "train loss 0.5339999794960022\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "starting epoch 17\n",
      "Epoch:18\n",
      "train loss 0.5389999747276306\n",
      "val loss 0.5289999842643738\n",
      "test loss 0.531000018119812\n",
      "\n",
      "Finished Training after 18 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.621999979019165\n",
      "val loss 0.621999979019165\n",
      "test loss 0.6209999918937683\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.9 wd:0.01\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.515999972820282\n",
      "val loss 0.5230000019073486\n",
      "test loss 0.5199999809265137\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.5\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.49300000071525574\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.49000000953674316\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.5009999871253967\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.5040000081062317\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.49799999594688416\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.5\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.5019999742507935\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.49300000071525574\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.48399999737739563\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.48899999260902405\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 16\n",
      "Epoch:17\n",
      "train loss 0.49300000071525574\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 17\n",
      "Epoch:18\n",
      "train loss 0.5019999742507935\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 18\n",
      "Epoch:19\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.4950000047683716\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 19\n",
      "Epoch:20\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.4959999918937683\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 20\n",
      "Epoch:21\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 21\n",
      "Epoch:22\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 22\n",
      "Epoch:23\n",
      "train loss 0.49399998784065247\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 23\n",
      "Epoch:24\n",
      "train loss 0.4909999966621399\n",
      "val loss 0.4950000047683716\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "Finished Training after 24 epochs\n",
      "save_folder:results_mlp_ingre_bucket\n",
      "inital eval\n",
      "Epoch:0\n",
      "train loss 0.6430000066757202\n",
      "val loss 0.640999972820282\n",
      "test loss 0.640999972820282\n",
      "\n",
      "Entering train loop for lr:0.001 p:0.9 wd:0.001\n",
      "starting epoch 0\n",
      "Epoch:1\n",
      "train loss 0.515999972820282\n",
      "val loss 0.5180000066757202\n",
      "test loss 0.5149999856948853\n",
      "\n",
      "starting epoch 1\n",
      "Epoch:2\n",
      "train loss 0.4959999918937683\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 2\n",
      "Epoch:3\n",
      "train loss 0.5009999871253967\n",
      "val loss 0.5049999952316284\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 3\n",
      "Epoch:4\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 4\n",
      "Epoch:5\n",
      "train loss 0.4950000047683716\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.4970000088214874\n",
      "\n",
      "starting epoch 5\n",
      "Epoch:6\n",
      "train loss 0.48100000619888306\n",
      "val loss 0.5\n",
      "test loss 0.492000013589859\n",
      "\n",
      "starting epoch 6\n",
      "Epoch:7\n",
      "train loss 0.4869999885559082\n",
      "val loss 0.49900001287460327\n",
      "test loss 0.49000000953674316\n",
      "\n",
      "starting epoch 7\n",
      "Epoch:8\n",
      "train loss 0.49000000953674316\n",
      "val loss 0.4970000088214874\n",
      "test loss 0.48899999260902405\n",
      "\n",
      "starting epoch 8\n",
      "Epoch:9\n",
      "train loss 0.4970000088214874\n",
      "val loss 0.5109999775886536\n",
      "test loss 0.5009999871253967\n",
      "\n",
      "starting epoch 9\n",
      "Epoch:10\n",
      "train loss 0.48100000619888306\n",
      "val loss 0.5\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 10\n",
      "Epoch:11\n",
      "train loss 0.4880000054836273\n",
      "val loss 0.49799999594688416\n",
      "test loss 0.4909999966621399\n",
      "\n",
      "starting epoch 11\n",
      "Epoch:12\n",
      "train loss 0.4860000014305115\n",
      "val loss 0.503000020980835\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 12\n",
      "Epoch:13\n",
      "train loss 0.4830000102519989\n",
      "val loss 0.5040000081062317\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 13\n",
      "Epoch:14\n",
      "train loss 0.48100000619888306\n",
      "val loss 0.503000020980835\n",
      "test loss 0.49399998784065247\n",
      "\n",
      "starting epoch 14\n",
      "Epoch:15\n",
      "train loss 0.4779999852180481\n",
      "val loss 0.5019999742507935\n",
      "test loss 0.49300000071525574\n",
      "\n",
      "starting epoch 15\n",
      "Epoch:16\n",
      "train loss 0.48100000619888306\n",
      "val loss 0.5059999823570251\n",
      "test loss 0.4959999918937683\n",
      "\n",
      "Finished Training after 16 epochs\n"
     ]
    }
   ],
   "source": [
    "for lr in tqdm([1e-1,1e-2,1e-3]):\n",
    "    for p in [0.8,0.9]:\n",
    "        for wd in [1e-1,1e-2,1e-3]:\n",
    "            if lr == wd:\n",
    "                continue\n",
    "            trial(64, lr, p, wd,'results_mlp_ingre_regression',reg=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
